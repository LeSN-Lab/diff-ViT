{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import math\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "import time\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from model_utility import *\n",
    "from dataset_utility import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "from cka_utility import *\n",
    "# from seaborn import heatmap\n",
    "\n",
    "from config import Config\n",
    "from models import *\n",
    "\n",
    "import numpy as np\n",
    "from plot import *\n",
    "parser = argparse.ArgumentParser(description='FQ-ViT')\n",
    "\n",
    "parser.add_argument('--model',\n",
    "                    choices=[\n",
    "                        'deit_tiny', 'deit_small', 'deit_base', 'vit_base',\n",
    "                        'vit_large', 'swin_tiny', 'swin_small', 'swin_base'\n",
    "                    ],\n",
    "                    default='deit_tiny',\n",
    "                    help='model')\n",
    "parser.add_argument('--data', metavar='DIR',\n",
    "                    default='/data/deepops/temp/easy-lora-and-gptq/imagenet',\n",
    "                    help='path to dataset')\n",
    "parser.add_argument('--quant', default=True, action='store_true')\n",
    "parser.add_argument('--ptf', default=False)\n",
    "parser.add_argument('--lis', default=False)\n",
    "parser.add_argument('--quant-method',\n",
    "                    default='minmax',\n",
    "                    choices=['minmax', 'ema', 'omse', 'percentile'])\n",
    "parser.add_argument('--mixed', default=True, action='store_true')\n",
    "# TODO: 100 --> 32\n",
    "parser.add_argument('--calib-batchsize',\n",
    "                    default=100,\n",
    "                    type=int,\n",
    "                    help='batchsize of calibration set')\n",
    "parser.add_argument(\"--mode\", default=0,\n",
    "                        type=int, \n",
    "                        help=\"mode of calibration data, 0: PSAQ-ViT, 1: Gaussian noise, 2: Real data\")\n",
    "# TODO: 10 --> 1\n",
    "parser.add_argument('--calib-iter', default=10, type=int)\n",
    "# TODO: 100 --> 200\n",
    "parser.add_argument('--val-batchsize',\n",
    "                    default=200,\n",
    "                    type=int,\n",
    "                    help='batchsize of validation set')\n",
    "parser.add_argument('--num-workers',\n",
    "                    default=16,\n",
    "                    type=int,\n",
    "                    help='number of data loading workers (default: 16)')\n",
    "parser.add_argument('--device', default='cuda', type=str, help='device')\n",
    "parser.add_argument('--print-freq',\n",
    "                    default=100,\n",
    "                    type=int,\n",
    "                    help='print frequency')\n",
    "parser.add_argument('--seed', default=0, type=int, help='seed')\n",
    "\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "seed(args.seed)\n",
    "\n",
    "device = torch.device(args.device)\n",
    "cfg = Config(args.ptf, args.lis, args.quant_method)\n",
    "# model = str2model(args.model)(pretrained=True, cfg=cfg)\n",
    "# model = model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "# Note: Different models have different strategies of data preprocessing.\n",
    "model_type = args.model.split('_')[0]\n",
    "if model_type == 'deit':\n",
    "    mean = (0.485, 0.456, 0.406)\n",
    "    std = (0.229, 0.224, 0.225)\n",
    "    crop_pct = 0.875\n",
    "elif model_type == 'vit':\n",
    "    mean = (0.5, 0.5, 0.5)\n",
    "    std = (0.5, 0.5, 0.5)\n",
    "    crop_pct = 0.9\n",
    "elif model_type == 'swin':\n",
    "    mean = (0.485, 0.456, 0.406)\n",
    "    std = (0.229, 0.224, 0.225)\n",
    "    crop_pct = 0.9\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "train_transform = build_transform(mean=mean, std=std, crop_pct=crop_pct)\n",
    "val_transform = build_transform(mean=mean, std=std, crop_pct=crop_pct)\n",
    "\n",
    "# Data\n",
    "traindir = os.path.join(args.data, 'train')\n",
    "valdir = os.path.join(args.data, 'val')\n",
    "\n",
    "val_dataset = datasets.ImageFolder(valdir, val_transform)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=args.val_batchsize,\n",
    "    shuffle=False,\n",
    "    num_workers=args.num_workers,\n",
    "    pin_memory=True,\n",
    ")\n",
    "# switch to evaluate mode\n",
    "# model.eval()\n",
    "\n",
    "# define loss function (criterion)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "train_dataset = datasets.ImageFolder(traindir, train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=10,\n",
    "    shuffle=True,\n",
    "    num_workers=args.num_workers,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: deit_tiny_patch16_224\n",
      "Model: deit_tiny_patch16_224\n",
      "Calibrating with real data...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# int8_model = model_make(args.model, args.ptf, args.lis, args.quant_method, args.device)\n",
    "int4_model = model_make(args.model, args.ptf, args.lis, args.quant_method, args.device)\n",
    "not_quantized_model = model_make(args.model, args.ptf, args.lis, args.quant_method, args.device)\n",
    "\n",
    "restore_indices = [8, 19]\n",
    "\n",
    "# eight_bit_config = [8]*50\n",
    "#basic_net, epsilon, step_size, num_steps, bit_config, args\n",
    "not_quantized_attack_net = AttackPGD(\n",
    "    basic_net=not_quantized_model, \n",
    "    epsilon=0.06,\n",
    "    step_size=0.01,\n",
    "    num_steps=50,\n",
    "    bit_config=None,\n",
    "    args=args)\n",
    "\n",
    "four_bit_config = [4]*50\n",
    "for idx in restore_indices:\n",
    "    four_bit_config[idx] = -1\n",
    "\n",
    "seed_images, seed_labels = not_quantized_attack_net.get_seed_inputs(50, rand=False)\n",
    "adv_inputs = not_quantized_attack_net.gen_adv_inputs(seed_images, seed_labels)\n",
    "\n",
    "# int8_model = calibrate_model(args.mode, args, int8_model, train_loader, device)\n",
    "int4_model = calibrate_model(args.mode, args, int4_model, train_loader, device)\n",
    "\n",
    "\n",
    "# int8_model.eval()\n",
    "int4_model.eval()\n",
    "not_quantized_model.eval()\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (50) must match the size of tensor b (49) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcompute_cka_with_adversarial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnot_quantized_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mint4_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                             \u001b[49m\u001b[43muse_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mnormalize_act\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcka_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#원래는 cifar10 256장.\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcka_iter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mresult_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m4to32_false_top5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mmodel1_bit_config\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mmodel2_bit_config\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfour_bit_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                             \u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/deepops/temp/diff-ViT/cka_utility.py:252\u001b[0m, in \u001b[0;36mcompute_cka_with_adversarial\u001b[0;34m(model1, model2, use_batch, normalize_act, cka_batch, cka_batch_iter, cka_iter, result_name, model1_bit_config, model2_bit_config, args)\u001b[0m\n\u001b[1;32m    239\u001b[0m model2_get_activation \u001b[38;5;241m=\u001b[39m get_activations(\n\u001b[1;32m    240\u001b[0m     images\u001b[38;5;241m=\u001b[39mimages,\n\u001b[1;32m    241\u001b[0m     model \u001b[38;5;241m=\u001b[39m model2,\n\u001b[1;32m    242\u001b[0m     bit_config\u001b[38;5;241m=\u001b[39mmodel2_bit_config,\n\u001b[1;32m    243\u001b[0m     device\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice,\n\u001b[1;32m    244\u001b[0m     normalize_act\u001b[38;5;241m=\u001b[39mnormalize_act)\n\u001b[1;32m    245\u001b[0m model2_get_adv_activation \u001b[38;5;241m=\u001b[39m get_activations(\n\u001b[1;32m    246\u001b[0m     images\u001b[38;5;241m=\u001b[39madv_images,\n\u001b[1;32m    247\u001b[0m     model \u001b[38;5;241m=\u001b[39m model2,\n\u001b[1;32m    248\u001b[0m     bit_config\u001b[38;5;241m=\u001b[39mmodel2_bit_config,\n\u001b[1;32m    249\u001b[0m     device\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice,\n\u001b[1;32m    250\u001b[0m     normalize_act\u001b[38;5;241m=\u001b[39mnormalize_act)\n\u001b[0;32m--> 252\u001b[0m \u001b[43mcka\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel1_activations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel1_get_activation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmodel1_adv_activations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel1_get_adv_activation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmodel2_activations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel2_get_activation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmodel2_adv_activations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel2_get_adv_activation\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#레이어 마다의 activation을 다 가져옴. 예를 들어 24 * 50 * feature^2. \u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m current_iter \u001b[38;5;241m>\u001b[39m cka_batch_iter:\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/data/deepops/temp/diff-ViT/DDV_CKA.py:51\u001b[0m, in \u001b[0;36mMinibatchAdvCKA.update_state\u001b[0;34m(self, model1_activations, model1_adv_activations, model2_activations, model2_adv_activations)\u001b[0m\n\u001b[1;32m     47\u001b[0m model2_layer_grams \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_adv_gram_matrix(x, adv_x) \u001b[38;5;28;01mfor\u001b[39;00m x, adv_x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(model2_activations, model2_adv_activations)])\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m#평균이 0인 것을 계속 더한다. 레이어별 유사도 (50, 2500), (50, 2500)을 내적하면 각 레이어마다의 유사도가 나온다.\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhsic_accumulator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel1_layer_grams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel2_layer_grams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhsic_accumulator_model1\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39madd_(torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mij,ij->i\u001b[39m\u001b[38;5;124m'\u001b[39m, model1_layer_grams, model1_layer_grams))\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhsic_accumulator_model2\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39madd_(torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mij,ij->i\u001b[39m\u001b[38;5;124m'\u001b[39m, model2_layer_grams, model2_layer_grams))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (50) must match the size of tensor b (49) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "compute_cka_with_adversarial(not_quantized_model,\n",
    "                             int4_model, \n",
    "                             use_batch = True, \n",
    "                             normalize_act = False, \n",
    "                             cka_batch = 50, #원래는 cifar10 256장.\n",
    "                             cka_iter = 15, \n",
    "                             result_name='4to32_false_top5', \n",
    "                             model1_bit_config = None,\n",
    "                             model2_bit_config = four_bit_config,\n",
    "                             args = args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_cka_with_adversarial(not_quantized_model,\n",
    "                             int8_model, \n",
    "                             use_batch = True, \n",
    "                             normalize_act = False, \n",
    "                             cka_batch = 50, #원래는 cifar10 256장.\n",
    "                             cka_iter = 15, \n",
    "                             result_name='false_cka_with_adversarial_not_quantized_int8_model_test', \n",
    "                             model1_bit_config = None,\n",
    "                             model2_bit_config = eight_bit_config,\n",
    "                             args = args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_cka_map(\n",
    "    cka_file_name= '4to32_true_top5', \n",
    "    plot_name = '4to32_true_top5',\n",
    "    base_dir= '/data/deepops/temp/diff-ViT'\n",
    "    )\n",
    "\n",
    "\n",
    "# 사용 예시\n",
    "pickle_folder = '4to32_true_top5'\n",
    "#qkv, proj, mlp_fc1, mlp_fc2\n",
    "\n",
    "comprehensive_pickle_file = f'{pickle_folder}/4to32_true_top5_heatmap'\n",
    "\n",
    "qkv_pickle_file = f'{pickle_folder}/cka_qkv'\n",
    "proj_pickle_file = f'{pickle_folder}/cka_proj'\n",
    "mlp_fc1_pickle_file = f'{pickle_folder}/cka_mlp_fc1'\n",
    "mlp_fc2_pickle_file = f'{pickle_folder}/cka_mlp_fc2'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "comprehensive_diagonal = load_and_plot_diagonal(comprehensive_pickle_file)\n",
    "qkv_diagonal = load_and_plot_diagonal(qkv_pickle_file)\n",
    "proj_diagonal = load_and_plot_diagonal(proj_pickle_file)\n",
    "mlp_fc1_diagonal = load_and_plot_diagonal(mlp_fc1_pickle_file)\n",
    "mlp_fc2_diagonal = load_and_plot_diagonal(mlp_fc2_pickle_file)\n",
    "\n",
    "\n",
    "# 대각 값들 출력\n",
    "print(\"comprehensive_Diagonal values:\", comprehensive_diagonal)\n",
    "print(\"qkv_Diagonal values:\", qkv_diagonal)\n",
    "print(\"proj_Diagonal values:\", proj_diagonal)\n",
    "print(\"mlp_fc1_Diagonal values:\", mlp_fc1_diagonal)\n",
    "print(\"mlp_fc2_Diagonal values:\", mlp_fc2_diagonal)\n",
    "\n",
    "\n",
    "\n",
    "pickle_files = [\n",
    "    f'{pickle_folder}/4to32_true_top5_heatmap',\n",
    "    f'{pickle_folder}/cka_qkv',\n",
    "    f'{pickle_folder}/cka_proj',\n",
    "    f'{pickle_folder}/cka_mlp_fc1',\n",
    "    f'{pickle_folder}/cka_mlp_fc2'\n",
    "]\n",
    "\n",
    "labels = ['Comprehensive', 'QKV', 'Proj', 'MLP FC1', 'MLP FC2']\n",
    "\n",
    "plot_all_diagonals(pickle_files, labels)\n",
    "\n",
    "# 대각 값들 출력\n",
    "for pickle_file, label in zip(pickle_files, labels):\n",
    "    diagonal = load_diagonal(pickle_file)\n",
    "    print(f\"{label} Diagonal values:\", diagonal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 주어진 데이터\n",
    "diagonal_values = [0.9844448, 0.9932241, 0.93696433, 0.9890642, 0.98236245, 0.98273927,\n",
    " 0.9669165, 0.97682315, 0.96053445, 0.93956995, 0.883112, 0.9153894,\n",
    " 0.82392144, 0.94314486, 0.87513494, 0.8596895, 0.78642637, 0.9355694,\n",
    " 0.78753734, 0.8946206, 0.75526136, 0.8556227, 0.7713002, 0.8730264,\n",
    " 0.7159015, 0.8325918, 0.7855737, 0.85561025, 0.7514658, 0.834453,\n",
    " 0.7451548, 0.79941905, 0.7197552, 0.82510316, 0.6981765, 0.76884013,\n",
    " 0.6962489, 0.783298, 0.6163095, 0.80576235, 0.63277966, 0.76214015,\n",
    " 0.5590432, 0.7734749, 0.5422483, 0.7486398, 0.32279363, 0.61376655,\n",
    " 0.58972996, 0.44388658]\n",
    "\n",
    "\n",
    "# 기울기 계산\n",
    "slopes = np.diff(diagonal_values)\n",
    "\n",
    "# 음수 기울기만 선택\n",
    "negative_slopes = slopes[slopes < 0]\n",
    "negative_slopes_indices = np.where(slopes < 0)[0]\n",
    "\n",
    "# 음수 기울기 중 절댓값이 가장 큰 5개의 기울기 쌍 찾기\n",
    "abs_negative_slopes = np.abs(negative_slopes)\n",
    "top_5_indices = np.argsort(abs_negative_slopes)[-6:][::-1]\n",
    "top_5_pairs = [(negative_slopes_indices[i], negative_slopes_indices[i]+1, negative_slopes[i]) for i in top_5_indices]\n",
    "\n",
    "# 그래프 그리기\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, 50), np.where(slopes < 0, np.abs(slopes), np.nan), marker='o')\n",
    "plt.title('Absolute Values of Negative Slopes between Adjacent Layers')\n",
    "plt.xlabel('Layer')\n",
    "plt.ylabel('Absolute Slope Value')\n",
    "plt.xticks(range(0, 50, 5))\n",
    "plt.grid(True)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"음수 기울기 중 절댓값이 가장 큰 5개의 기울기 쌍:\")\n",
    "for pair in top_5_pairs:\n",
    "    print(f\"Layers {pair[0]+1}-{pair[1]+1}: {pair[2]:.6f}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_cka_map(\n",
    "    cka_file_name= 'false_cka_with_adversarial_not_quantized_int8_model_test', \n",
    "    plot_name = 'false_cka_with_adversarial_not_quantized_int8_model_test',\n",
    "    base_dir= '/data/deepops/temp/diff-ViT'\n",
    "    )\n",
    "\n",
    "\n",
    "# 사용 예시\n",
    "pickle_folder = 'false_cka_with_adversarial_not_quantized_int8_model_test'\n",
    "#qkv, proj, mlp_fc1, mlp_fc2\n",
    "\n",
    "comprehensive_pickle_file = f'{pickle_folder}/false_cka_with_adversarial_not_quantized_int8_model_test_heatmap'\n",
    "\n",
    "qkv_pickle_file = f'{pickle_folder}/cka_qkv'\n",
    "proj_pickle_file = f'{pickle_folder}/cka_proj'\n",
    "mlp_fc1_pickle_file = f'{pickle_folder}/cka_mlp_fc1'\n",
    "mlp_fc2_pickle_file = f'{pickle_folder}/cka_mlp_fc2'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "comprehensive_diagonal = load_and_plot_diagonal(comprehensive_pickle_file)\n",
    "qkv_diagonal = load_and_plot_diagonal(qkv_pickle_file)\n",
    "proj_diagonal = load_and_plot_diagonal(proj_pickle_file)\n",
    "mlp_fc1_diagonal = load_and_plot_diagonal(mlp_fc1_pickle_file)\n",
    "mlp_fc2_diagonal = load_and_plot_diagonal(mlp_fc2_pickle_file)\n",
    "\n",
    "\n",
    "# 대각 값들 출력\n",
    "print(\"comprehensive_Diagonal values:\", comprehensive_diagonal)\n",
    "print(\"qkv_Diagonal values:\", qkv_diagonal)\n",
    "print(\"proj_Diagonal values:\", proj_diagonal)\n",
    "print(\"mlp_fc1_Diagonal values:\", mlp_fc1_diagonal)\n",
    "print(\"mlp_fc2_Diagonal values:\", mlp_fc2_diagonal)\n",
    "\n",
    "\n",
    "\n",
    "pickle_files = [\n",
    "    f'{pickle_folder}/false_cka_with_adversarial_not_quantized_int8_model_test_heatmap',\n",
    "    f'{pickle_folder}/cka_qkv',\n",
    "    f'{pickle_folder}/cka_proj',\n",
    "    f'{pickle_folder}/cka_mlp_fc1',\n",
    "    f'{pickle_folder}/cka_mlp_fc2'\n",
    "]\n",
    "\n",
    "labels = ['Comprehensive', 'QKV', 'Proj', 'MLP FC1', 'MLP FC2']\n",
    "\n",
    "plot_all_diagonals(pickle_files, labels)\n",
    "\n",
    "# 대각 값들 출력\n",
    "for pickle_file, label in zip(pickle_files, labels):\n",
    "    diagonal = load_diagonal(pickle_file)\n",
    "    print(f\"{label} Diagonal values:\", diagonal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptq4vit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
