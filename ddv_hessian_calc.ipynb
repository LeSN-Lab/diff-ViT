{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lesn/.conda/envs/diffvit/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import math\n",
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "import time\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from model_utility import *\n",
    "from dataset_utility import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "from cka_utility import *\n",
    "# from seaborn import heatmap\n",
    "\n",
    "from config import Config\n",
    "from models import *\n",
    "\n",
    "import numpy as np\n",
    "from plot import *\n",
    "parser = argparse.ArgumentParser(description='FQ-ViT')\n",
    "\n",
    "parser.add_argument('--model',\n",
    "                    choices=[\n",
    "                        'deit_tiny', 'deit_small', 'deit_base', 'vit_base',\n",
    "                        'vit_large', 'swin_tiny', 'swin_small', 'swin_base'\n",
    "                    ],\n",
    "                    default='deit_tiny',\n",
    "                    help='model')\n",
    "parser.add_argument('--data', metavar='DIR',\n",
    "                    default='/home/lesn/quantctr/imagenet',\n",
    "                    help='path to dataset')\n",
    "parser.add_argument('--quant', default=True, action='store_true')\n",
    "parser.add_argument('--ptf', default=False)\n",
    "parser.add_argument('--lis', default=False)\n",
    "parser.add_argument('--quant-method',\n",
    "                    default='minmax',\n",
    "                    choices=['minmax', 'ema', 'omse', 'percentile'])\n",
    "parser.add_argument('--mixed', default=True, action='store_true')\n",
    "# TODO: 100 --> 32\n",
    "parser.add_argument('--calib-batchsize',\n",
    "                    default=10,\n",
    "                    type=int,\n",
    "                    help='batchsize of calibration set')\n",
    "parser.add_argument(\"--mode\", default=0,\n",
    "                        type=int, \n",
    "                        help=\"mode of calibration data, 0: PSAQ-ViT, 1: Gaussian noise, 2: Real data\")\n",
    "# TODO: 10 --> 1\n",
    "parser.add_argument('--calib-iter', default=10, type=int)\n",
    "# TODO: 100 --> 200\n",
    "parser.add_argument('--val-batchsize',\n",
    "                    default=10,\n",
    "                    type=int,\n",
    "                    help='batchsize of validation set')\n",
    "parser.add_argument('--num-workers',\n",
    "                    default=16,\n",
    "                    type=int,\n",
    "                    help='number of data loading workers (default: 16)')\n",
    "parser.add_argument('--device', default='cuda', type=str, help='device')\n",
    "parser.add_argument('--print-freq',\n",
    "                    default=100,\n",
    "                    type=int,\n",
    "                    help='print frequency')\n",
    "parser.add_argument('--seed', default=0, type=int, help='seed')\n",
    "\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "seed(args.seed)\n",
    "\n",
    "device = torch.device(args.device)\n",
    "cfg = Config(args.ptf, args.lis, args.quant_method)\n",
    "# model = str2model(args.model)(pretrained=True, cfg=cfg)\n",
    "# model = model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "# Note: Different models have different strategies of data preprocessing.\n",
    "model_type = args.model.split('_')[0]\n",
    "if model_type == 'deit':\n",
    "    mean = (0.485, 0.456, 0.406)\n",
    "    std = (0.229, 0.224, 0.225)\n",
    "    crop_pct = 0.875\n",
    "elif model_type == 'vit':\n",
    "    mean = (0.5, 0.5, 0.5)\n",
    "    std = (0.5, 0.5, 0.5)\n",
    "    crop_pct = 0.9\n",
    "elif model_type == 'swin':\n",
    "    mean = (0.485, 0.456, 0.406)\n",
    "    std = (0.229, 0.224, 0.225)\n",
    "    crop_pct = 0.9\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "train_transform = build_transform(mean=mean, std=std, crop_pct=crop_pct)\n",
    "val_transform = build_transform(mean=mean, std=std, crop_pct=crop_pct)\n",
    "\n",
    "# Data\n",
    "traindir = os.path.join(args.data, 'train')\n",
    "valdir = os.path.join(args.data, 'val')\n",
    "\n",
    "val_dataset = datasets.ImageFolder(valdir, val_transform)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=args.val_batchsize,\n",
    "    shuffle=False,\n",
    "    num_workers=args.num_workers,\n",
    "    pin_memory=True,\n",
    ")\n",
    "# switch to evaluate mode\n",
    "# model.eval()\n",
    "\n",
    "# define loss function (criterion)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "train_dataset = datasets.ImageFolder(traindir, train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=5,\n",
    "    shuffle=True,\n",
    "    num_workers=args.num_workers,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: deit_tiny_patch16_224\n",
      "Model: deit_tiny_patch16_224\n",
      "Calibrating with real data...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# int8_model = model_make(args.model, args.ptf, args.lis, args.quant_method, args.device)\n",
    "int4_model = model_make(args.model, args.ptf, args.lis, args.quant_method, args.device)\n",
    "not_quantized_model = model_make(args.model, args.ptf, args.lis, args.quant_method, args.device)\n",
    "\n",
    "restore_indices = [8, 19]\n",
    "\n",
    "# eight_bit_config = [8]*50\n",
    "#basic_net, epsilon, step_size, num_steps, bit_config, args\n",
    "not_quantized_attack_net = AttackPGD(\n",
    "    basic_net=not_quantized_model, \n",
    "    epsilon=0.06,\n",
    "    step_size=0.01,\n",
    "    num_steps=50,\n",
    "    bit_config=None,\n",
    "    args=args)\n",
    "\n",
    "four_bit_config = [4]*50\n",
    "\n",
    "\n",
    "seed_images, seed_labels = not_quantized_attack_net.get_seed_inputs(50, rand=False)\n",
    "adv_inputs = not_quantized_attack_net.gen_adv_inputs(seed_images, seed_labels)\n",
    "\n",
    "# int8_model = calibrate_model(args.mode, args, int8_model, train_loader, device)\n",
    "int4_model = calibrate_model(args.mode, args, int4_model, train_loader, device)\n",
    "\n",
    "\n",
    "# int8_model.eval()\n",
    "int4_model.eval()\n",
    "not_quantized_model.eval()\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating the sensitiveties via the averaged Hessian trace.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lesn/.conda/envs/diffvit/lib/python3.9/site-packages/torch/autograd/graph.py:769: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at ../torch/csrc/autograd/engine.cpp:1203.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 7.66 GiB of which 18.81 MiB is free. Including non-PyTorch memory, this process has 7.62 GiB memory in use. Of the allocated memory 6.99 GiB is allocated by PyTorch, and 461.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m trace_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (inputs, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m---> 11\u001b[0m     hessian_comp \u001b[38;5;241m=\u001b[39m \u001b[43mDDV_hessian\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mquantized_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mint4_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                    \u001b[49m\u001b[43moriginal_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnot_quantized_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                    \u001b[49m\u001b[43madv_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43madv_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m현재 몇번쨰?\u001b[39m\u001b[38;5;124m\"\u001b[39m, i)\n\u001b[1;32m     19\u001b[0m     name, trace \u001b[38;5;241m=\u001b[39m hessian_comp\u001b[38;5;241m.\u001b[39mtrace()\n",
      "File \u001b[0;32m~/quantctr/diff-ViT/pyhessian/ddv_hessian.py:101\u001b[0m, in \u001b[0;36mDDV_hessian.__init__\u001b[0;34m(self, quantized_model, original_model, criterion, data, adv_data, dataloader, adv_dataloader, cuda)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;66;03m# loss = self.criterion(outputs[0], self.targets)\u001b[39;00m\n\u001b[1;32m    100\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(quantized_ddv, original_ddv\u001b[38;5;241m.\u001b[39mdetach())\n\u001b[0;32m--> 101\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# this step is used to extract the parameters from the model\u001b[39;00m\n\u001b[1;32m    104\u001b[0m params, names, gradsH \u001b[38;5;241m=\u001b[39m get_params_grad(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquantized_model)\n",
      "File \u001b[0;32m~/.conda/envs/diffvit/lib/python3.9/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/diffvit/lib/python3.9/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/diffvit/lib/python3.9/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 7.66 GiB of which 18.81 MiB is free. Including non-PyTorch memory, this process has 7.62 GiB memory in use. Of the allocated memory 6.99 GiB is allocated by PyTorch, and 461.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# # TODO: Compute the hessian metrics\n",
    "    \n",
    "from pyhessian import DDV_hessian\n",
    "\n",
    "# # TODO:\n",
    "# #####################################################\n",
    "print(\"Calculating the sensitiveties via the averaged Hessian trace.......\")\n",
    "batch_num = 10\n",
    "trace_list = []\n",
    "for i, (inputs, labels) in enumerate(train_loader):\n",
    "    hessian_comp = DDV_hessian(\n",
    "                    quantized_model=int4_model, \n",
    "                    original_model=not_quantized_model,\n",
    "                    criterion=criterion,\n",
    "                    data=(inputs, labels),\n",
    "                    adv_data = (adv_inputs, labels),\n",
    "                    cuda=args.device)\n",
    "    print(\"현재 몇번쨰?\", i)\n",
    "    name, trace = hessian_comp.trace()\n",
    "    trace_list.append(trace)\n",
    "    if i == batch_num - 1:\n",
    "        break\n",
    "\n",
    "# top_eigenvalues, _ = hessian_comp.eigenvalues()\n",
    "# trace = hessian_comp.trace()\n",
    "# density_eigen, density_weight = hessian_comp.density()\n",
    "# print('\\n***Top Eigenvalues: ', top_eigenvalues)\n",
    "\n",
    "new_global_hessian_track = []\n",
    "for i in range(int(len(trace_list))):\n",
    "    hessian_track = trace_list[i]\n",
    "    hessian_track = [abs(x) for x in hessian_track]\n",
    "    min_h = min(hessian_track)\n",
    "    max_h = max(hessian_track)\n",
    "    averaged_hessian_track = [(elem-min_h)/(max_h-min_h) for elem in hessian_track]\n",
    "    new_global_hessian_track.append(averaged_hessian_track)\n",
    "\n",
    "\n",
    "# min_hessian = []\n",
    "# max_hessian = []\n",
    "layer_num = len(trace_list[0])\n",
    "for i in range(layer_num):\n",
    "    new_hessian = [sample[i] for sample in new_global_hessian_track]\n",
    "    mean_hessian.append(sum(new_hessian)/len(new_hessian))\n",
    "    # min_hessian.append(min(new_hessian))\n",
    "    # max_hessian.append(max(new_hessian))\n",
    "\n",
    "print(name)\n",
    "print('\\n***Trace: ', mean_hessian)\n",
    "    # # exit()\n",
    "    # ################ deit-base ################\n",
    "    # mean_hessian = [0.1728846995274323, 0.5223890107224295, 0.8191925959786669, 0.7076886016952384, 0.024708840222082775, 0.06145297177505395, 0.13322631271040494, 0.06554926888319061, 0.06175339225459908, 0.030678026107910893, 0.24494822213016829, 0.06636346426025085, 0.15758525560166742, 0.04395577998269693, 0.14552961945368617, 0.060864547749392026, 0.08752683209414383, 0.05799105819299426, 0.22538750132546922, 0.06785646981946868, 0.07478358821405745, 0.036487501147269154, 0.07572471890381866, 0.04584776940321937, 0.0906965395135412, 0.052852272764886334, 0.07057863784461312, 0.054111013841287636, 0.10702172109786383, 0.06730713583013927, 0.15666245711129553, 0.062172999291384645, 0.14509012240011504, 0.091604835756826, 0.2623722516111311, 0.06393236780883862, 0.11330756525833534, 0.0961950553973105, 0.18536753690007585, 0.09250514367800573, 0.11291326692010435, 0.09088161815323087, 0.08509066277645735, 0.19602731888893016, 0.05031627704809997, 0.06092669320490903, 0.23648108326696252, 0.07698688576427923, 0.37813159586619466]\n",
    "    # ################ deit-tiny ################\n",
    "    # mean_hessian = [0.12777249535991195, 0.3047042506776798, 0.6836076810672933, 0.9160977695613777, 0.051443724472863196, 0.1917038465654385, 0.40636168841774706, 0.31831214126540874, 0.17167878599488856, 0.17040465195968652, 0.5848568924580573, 0.34105575377627256, 0.2250203702397191, 0.24419067521700116, 0.5773478063329939, 0.33414308463155074, 0.25956759388373196, 0.1395379949578424, 0.4314355169808728, 0.22188267697321334, 0.1817366766340382, 0.11851699436886039, 0.4161464737579431, 0.19327061829322395, 0.17012293934278208, 0.12277515606872576, 0.4558816353483174, 0.15589752294249398, 0.17898296918815426, 0.086547094124963, 0.3467772011352197, 0.08775692025611888, 0.15284702235308084, 0.10833365447369167, 0.25759808027283065, 0.08692103455348514, 0.10185882004871938, 0.06342371816526218, 0.0780091910106661, 0.03666006418635352, 0.11141181591383327, 0.035333162826754756, 0.09242800375426533, 0.06258579742709644, 0.16515551045287732, 0.017525156872452197, 0.13652986573803982, 0.12360630901916989, 0.5199713391368654]\n",
    "    #################  vit-base     #####################\n",
    "    # mean_hessian = [0.2548212292719357, 0.652774443906641, 0.4679151921750381, 0.701685889252979, 0.285828470166026, 0.23157499632195172, 0.3476872482482762, 0.1357167839246311, 0.15553461818570039, 0.08420512187074286, 0.13815553335403274, 0.05567239346066725, 0.05587586852723446, 0.026548078787158015, 0.040773535370026856, 0.04080585779417317, 0.042558716664201815, 0.01815925147754802, 0.0479197088365278, 0.0471326762460345, 0.04083466214898966, 0.028311625792593897, 0.05059781160702729, 0.05021307087351986, 0.053499192355708956, 0.03629001097533719, 0.05553639666005887, 0.05542365527998931, 0.07634114724354114, 0.04736352053579504, 0.048323007545345804, 0.050717087287928765, 0.04673213199666633, 0.0502429101251724, 0.06749587123992873, 0.06645178277549102, 0.06218872019962326, 0.05860797496787497, 0.08825207961909944, 0.059215633889038034, 0.05765285649664825, 0.050049860737162055, 0.11113519269279008, 0.04891473081609033, 0.06074138350325581, 0.048028355020529635, 0.03297529568771655, 0.039936908641505384, 0.4446260183369337]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptq4vit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
