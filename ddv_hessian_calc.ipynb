{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T06:56:48.621105Z",
     "start_time": "2024-11-03T06:56:48.097279Z"
    }
   },
   "source": [
    "import argparse\n",
    "import math\n",
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "import time\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from model_utility import *\n",
    "from dataset_utility import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "from cka_utility import *\n",
    "# from seaborn import heatmap\n",
    "\n",
    "from config import Config\n",
    "from models import *\n",
    "\n",
    "import numpy as np\n",
    "from plot import *\n",
    "parser = argparse.ArgumentParser(description='FQ-ViT')\n",
    "\n",
    "parser.add_argument('--model',\n",
    "                    choices=[\n",
    "                        'deit_tiny', 'deit_small', 'deit_base', 'vit_base',\n",
    "                        'vit_large', 'swin_tiny', 'swin_small', 'swin_base'\n",
    "                    ],\n",
    "                    default='deit_tiny',\n",
    "                    help='model')\n",
    "parser.add_argument('--data', metavar='DIR',\n",
    "                    default='/home/ubuntu/imagenet',\n",
    "                    help='path to dataset')\n",
    "parser.add_argument('--quant', default=True, action='store_true')\n",
    "parser.add_argument('--ptf', default=False)\n",
    "parser.add_argument('--lis', default=False)\n",
    "parser.add_argument('--quant-method',\n",
    "                    default='minmax',\n",
    "                    choices=['minmax', 'ema', 'omse', 'percentile'])\n",
    "parser.add_argument('--mixed', default=True, action='store_true')\n",
    "# TODO: 100 --> 32\n",
    "parser.add_argument('--calib-batchsize',\n",
    "                    default=50,\n",
    "                    type=int,\n",
    "                    help='batchsize of calibration set')\n",
    "parser.add_argument(\"--mode\", default=0,\n",
    "                        type=int, \n",
    "                        help=\"mode of calibration data, 0: PSAQ-ViT, 1: Gaussian noise, 2: Real data\")\n",
    "# TODO: 10 --> 1\n",
    "parser.add_argument('--calib-iter', default=10, type=int)\n",
    "# TODO: 100 --> 200\n",
    "parser.add_argument('--val-batchsize',\n",
    "                    default=200,\n",
    "                    type=int,\n",
    "                    help='batchsize of validation set')\n",
    "parser.add_argument('--num-workers',\n",
    "                    default=16,\n",
    "                    type=int,\n",
    "                    help='number of data loading workers (default: 16)')\n",
    "parser.add_argument('--device', default='cuda', type=str, help='device')\n",
    "parser.add_argument('--print-freq',\n",
    "                    default=100,\n",
    "                    type=int,\n",
    "                    help='print frequency')\n",
    "parser.add_argument('--seed', default=0, type=int, help='seed')\n",
    "\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "seed(args.seed)\n",
    "\n",
    "device = torch.device(args.device)\n",
    "cfg = Config(args.ptf, args.lis, args.quant_method)\n",
    "# model = str2model(args.model)(pretrained=True, cfg=cfg)\n",
    "# model = model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "# Note: Different models have different strategies of data preprocessing.\n",
    "model_type = args.model.split('_')[0]\n",
    "if model_type == 'deit':\n",
    "    mean = (0.485, 0.456, 0.406)\n",
    "    std = (0.229, 0.224, 0.225)\n",
    "    crop_pct = 0.875\n",
    "elif model_type == 'vit':\n",
    "    mean = (0.5, 0.5, 0.5)\n",
    "    std = (0.5, 0.5, 0.5)\n",
    "    crop_pct = 0.9\n",
    "elif model_type == 'swin':\n",
    "    mean = (0.485, 0.456, 0.406)\n",
    "    std = (0.229, 0.224, 0.225)\n",
    "    crop_pct = 0.9\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "train_transform = build_transform(mean=mean, std=std, crop_pct=crop_pct)\n",
    "val_transform = build_transform(mean=mean, std=std, crop_pct=crop_pct)\n",
    "\n",
    "# Data\n",
    "traindir = os.path.join(args.data, 'train')\n",
    "valdir = os.path.join(args.data, 'val')\n",
    "\n",
    "val_dataset = datasets.ImageFolder(valdir, val_transform)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=args.val_batchsize,\n",
    "    shuffle=False,\n",
    "    num_workers=args.num_workers,\n",
    "    pin_memory=True,\n",
    ")\n",
    "# switch to evaluate mode\n",
    "# model.eval()\n",
    "\n",
    "# define loss function (criterion)\n",
    "criterion = nn.MSELoss().to(device)\n",
    "\n",
    "train_dataset = datasets.ImageFolder(traindir, train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=args.calib_batchsize,\n",
    "    shuffle=True,\n",
    "    num_workers=args.num_workers,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    ")"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 7\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtime\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mrandom\u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mF\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmodel_utility\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdataset_utility\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'torch'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: deit_tiny_patch16_224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: deit_tiny_patch16_224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# int8_model = model_make(args.model, args.ptf, args.lis, args.quant_method, args.device)\n",
    "int4_model = model_make(args.model, args.ptf, args.lis, args.quant_method, args.device)\n",
    "not_quantized_model = model_make(args.model, args.ptf, args.lis, args.quant_method, args.device)\n",
    "\n",
    "# restore_indices = [8, 19]\n",
    "\n",
    "# eight_bit_config = [8]*50\n",
    "#basic_net, epsilon, step_size, num_steps, bit_config, args\n",
    "not_quantized_attack_net = AttackPGD(\n",
    "    basic_net=not_quantized_model, \n",
    "    epsilon=0.06,\n",
    "    step_size=0.01,\n",
    "    num_steps=50,\n",
    "    bit_config=None,\n",
    "    args=args)\n",
    "\n",
    "four_bit_config = [4]*50\n",
    "\n",
    "\n",
    "# seed_images, seed_labels = not_quantized_attack_net.get_seed_inputs(5, rand=False)\n",
    "# adv_inputs = not_quantized_attack_net.gen_adv_inputs(seed_images, seed_labels)\n",
    "\n",
    "# int8_model = calibrate_model(args.mode, args, int8_model, train_loader, device)\n",
    "# int4_model = calibrate_model(args.mode, args, int4_model, train_loader, device)\n",
    "\n",
    "\n",
    "# int8_model.eval()\n",
    "# int4_model.eval()\n",
    "# not_quantized_model.eval()\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyhessian import hessian\n",
    "\n",
    "# # # TODO:\n",
    "# # #####################################################\n",
    "# print(\"Calculating the sensitiveties via the averaged Hessian trace.......\")\n",
    "# batch_num = 10\n",
    "# trace_list = []\n",
    "# criterion = nn.CrossEntropyLoss().to(device)\n",
    "# for i, (inputs, labels) in enumerate(train_loader):\n",
    "#     hessian_comp = hessian(not_quantized_model,\n",
    "#                     criterion,\n",
    "#                     data=(inputs, labels),\n",
    "#                     cuda=args.device)\n",
    "#     print(\"현재 몇번쨰?\", i)\n",
    "#     name, trace = hessian_comp.trace()\n",
    "#     trace_list.append(trace)\n",
    "#     if i == batch_num - 1:\n",
    "#         break\n",
    "\n",
    "# # top_eigenvalues, _ = hessian_comp.eigenvalues()\n",
    "# # trace = hessian_comp.trace()\n",
    "# # density_eigen, density_weight = hessian_comp.density()\n",
    "# # print('\\n***Top Eigenvalues: ', top_eigenvalues)\n",
    "\n",
    "# new_global_hessian_track = []\n",
    "# for i in range(int(len(trace_list))):\n",
    "#     hessian_track = trace_list[i]\n",
    "#     hessian_track = [abs(x) for x in hessian_track]\n",
    "#     min_h = min(hessian_track)\n",
    "#     max_h = max(hessian_track)\n",
    "#     averaged_hessian_track = [(elem-min_h)/(max_h-min_h) for elem in hessian_track]\n",
    "#     new_global_hessian_track.append(averaged_hessian_track)\n",
    "\n",
    "\n",
    "# # min_hessian = []\n",
    "# # max_hessian = []\n",
    "# mean_hessian = []\n",
    "# layer_num = len(trace_list[0])\n",
    "# for i in range(layer_num):\n",
    "#     new_hessian = [sample[i] for sample in new_global_hessian_track]\n",
    "#     mean_hessian.append(sum(new_hessian)/len(new_hessian))\n",
    "#     # min_hessian.append(min(new_hessian))\n",
    "#     # max_hessian.append(max(new_hessian))\n",
    "\n",
    "# print(name)\n",
    "# print('\\n***Trace: ', mean_hessian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "# # # TODO:\n",
    "# # #####################################################\n",
    "# print(\"Calculating the sensitiveties via the averaged Hessian trace.......\")\n",
    "# batch_num = 10\n",
    "# trace_list = []\n",
    "# not_quantized_model.eval()\n",
    "# for i, (inputs, labels) in enumerate(train_loader):\n",
    "#     adv_inputs = not_quantized_attack_net.gen_adv_inputs(inputs, labels)\n",
    "        \n",
    "        \n",
    "#     inputs, targets = inputs.cuda(), labels.cuda()\n",
    "\n",
    "#     # if we only compute the Hessian information for a single batch data, we can re-use the gradients.\n",
    "#     normal_outputs, _, _ = not_quantized_model(inputs,  hessian_statistic=True)\n",
    "#     adv_outputs, _, _ = not_quantized_model(adv_inputs, hessian_statistic=True)\n",
    "#     original_ddv = torch.matmul(normal_outputs, adv_outputs.t())\n",
    "#     original_ddv = original_ddv.detach()\n",
    "#     print(\"현재 몇번쨰?\", i)\n",
    "#     hessian_comp = DDVHessian(\n",
    "#                     model = not_quantized_model,\n",
    "#                     q_model= int4_model,\n",
    "#                     criterion= torch.nn.MSELoss(),\n",
    "#                     data=(inputs, labels),\n",
    "#                     adv_data=(adv_inputs, labels),\n",
    "#                     original_ddv=original_ddv,\n",
    "#                     attack_net=not_quantized_attack_net,\n",
    "#                     cuda=args.device)\n",
    "    \n",
    "#     # for grad in hessian_comp.gradsH:\n",
    "#     #     print(grad.cpu().detach().numpy().sum())\n",
    "#     name, trace = hessian_comp.trace()\n",
    "#     trace_list.append(trace)\n",
    "#     if i == batch_num - 1:\n",
    "#         break\n",
    "\n",
    "# # top_eigenvalues, _ = hessian_comp.eigenvalues()\n",
    "# # trace = hessian_comp.trace()\n",
    "# # density_eigen, density_weight = hessian_comp.density()\n",
    "# # print('\\n***Top Eigenvalues: ', top_eigenvalues)\n",
    "\n",
    "# new_global_hessian_track = []\n",
    "# for i in range(int(len(trace_list))):\n",
    "#     hessian_track = trace_list[i]\n",
    "#     hessian_track = [abs(x) for x in hessian_track]\n",
    "#     min_h = min(hessian_track)\n",
    "#     max_h = max(hessian_track)\n",
    "#     averaged_hessian_track = [(elem-min_h)/(max_h-min_h) for elem in hessian_track]\n",
    "#     new_global_hessian_track.append(averaged_hessian_track)\n",
    "\n",
    "\n",
    "# # min_hessian = []\n",
    "# # max_hessian = []\n",
    "# layer_num = len(trace_list[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_hessian = []\n",
    "\n",
    "# for i in range(layer_num):\n",
    "#     new_hessian = [sample[i] for sample in new_global_hessian_track]\n",
    "#     mean_hessian.append(sum(new_hessian)/len(new_hessian))\n",
    "#     # min_hessian.append(min(new_hessian))\n",
    "#     # max_hessian.append(max(new_hessian))\n",
    "\n",
    "# print(name)\n",
    "# print('\\n***Trace: ', mean_hessian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# #ddv_hessian result\n",
    "# dh_data = [np.float64(0.1177874175069632), np.float64(0.3079008025314483), np.float64(0.6075554958688494), np.float64(1.0), np.float64(0.07821698416178048), np.float64(0.1955333071350255), np.float64(0.40127888402467055), np.float64(0.2838752739699172), np.float64(0.15095418877352407), np.float64(0.11820856377039632), np.float64(0.5166406866489658), np.float64(0.3399695649379112), np.float64(0.18781069030442923), np.float64(0.14687531772298695), np.float64(0.5226089516998274), np.float64(0.2689235259895636), np.float64(0.2060400941362838), np.float64(0.07209597790178655), np.float64(0.36436740955400165), np.float64(0.15389476896718252), np.float64(0.08123767133111293), np.float64(0.02751944648340926), np.float64(0.33751809608920463), np.float64(0.1596040988564092), np.float64(0.09439314566049087), np.float64(0.034284100699447435), np.float64(0.4028230468862494), np.float64(0.09627690304628482), np.float64(0.08412462954368802), np.float64(0.01046318222522866), np.float64(0.35576731244314375), np.float64(0.031088263868576937), np.float64(0.09626862791441057), np.float64(0.0390631356320333), np.float64(0.24585765421708672), np.float64(0.04642565503028732), np.float64(0.06702515322052251), np.float64(0.021899440386072284), np.float64(0.09214246551855504), np.float64(0.009694668797114402), np.float64(0.0770983640089043), np.float64(0.001766119927937541), np.float64(0.062463411873129246), np.float64(0.024433206593464624), np.float64(0.2560165376620039), np.float64(0.0024940805060462813), np.float64(0.1706602951599041), np.float64(0.08863532085132826), np.float64(0.07255832024490312)]\n",
    "# # 데이터\n",
    "# h_data =  [np.float64(0.32094153253371516), np.float64(0.45630186701573505), np.float64(0.46027244507048987), np.float64(0.778837614484494), np.float64(0.06803271888263146), np.float64(0.2651026572969264), np.float64(0.34762614370520195), np.float64(0.24576950173524778), np.float64(0.14522478811562511), np.float64(0.183265473436163), np.float64(0.4685355166353071), np.float64(0.28116584401638656), np.float64(0.18557367633130858), np.float64(0.19741098361054094), np.float64(0.3959751448411542), np.float64(0.30273725553180786), np.float64(0.2577341367269725), np.float64(0.14692009599275385), np.float64(0.4818070642016027), np.float64(0.25307655947561186), np.float64(0.18264605495607716), np.float64(0.1398189088036304), np.float64(0.4474852839027186), np.float64(0.2208056464760657), np.float64(0.2061968499447587), np.float64(0.1273108228158563), np.float64(0.530220292330312), np.float64(0.1822870738218118), np.float64(0.19431540297348476), np.float64(0.0948252594015712), np.float64(0.4049385154233212), np.float64(0.13258631555810402), np.float64(0.19401667197636482), np.float64(0.12192959061979511), np.float64(0.3148483680683384), np.float64(0.1120782487706864), np.float64(0.11810479281312165), np.float64(0.07956094672606405), np.float64(0.14698189904828382), np.float64(0.0514896730694905), np.float64(0.13057197621385722), np.float64(0.04516762398039), np.float64(0.10971315247471905), np.float64(0.08390269269160204), np.float64(0.1829256614692566), np.float64(0.02761632079446335), np.float64(0.15136467748834015), np.float64(0.1419573449597424), np.float64(0.5461621842825806)]\n",
    "\n",
    "\n",
    "\n",
    "# # numpy 배열로 변환\n",
    "# y1 = np.array(dh_data)\n",
    "# y2 = np.array(h_data)\n",
    "\n",
    "# # x 축 값 생성 (0부터 데이터 길이까지)\n",
    "# x = np.arange(len(y1))\n",
    "\n",
    "# # 그래프 그리기\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.plot(x, y1, marker='o', label='ddv_hessian result')\n",
    "# plt.plot(x, y2, marker='x', label='h_data')\n",
    "# plt.title('Data Comparison')\n",
    "# plt.xlabel('Index')\n",
    "# plt.ylabel('Value')\n",
    "# plt.legend()  # 범례 추가\n",
    "# plt.grid(True)\n",
    "\n",
    "# # 그래프 표시\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating the sensitivities via the averaged Hessian trace...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/diffvit/lib/python3.9/site-packages/torch/autograd/graph.py:769: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at ../torch/csrc/autograd/engine.cpp:1203.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1/10\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 25\u001B[0m\n\u001B[1;32m     14\u001B[0m hessian_comp \u001B[38;5;241m=\u001B[39m DDVHessian(\n\u001B[1;32m     15\u001B[0m     model\u001B[38;5;241m=\u001B[39mnot_quantized_model,\n\u001B[1;32m     16\u001B[0m     q_model\u001B[38;5;241m=\u001B[39mint4_model,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     22\u001B[0m     cuda\u001B[38;5;241m=\u001B[39margs\u001B[38;5;241m.\u001B[39mdevice\n\u001B[1;32m     23\u001B[0m )\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mProcessing batch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbatch_num\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 25\u001B[0m name, trace \u001B[38;5;241m=\u001B[39m \u001B[43mhessian_comp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrace\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     26\u001B[0m trace_list\u001B[38;5;241m.\u001B[39mappend(trace)\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m==\u001B[39m batch_num \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[0;32m~/diff-ViT/pyhessian/ddv_hessian.py:300\u001B[0m, in \u001B[0;36mDDVHessian.trace\u001B[0;34m(self, maxIter, tol)\u001B[0m\n\u001B[1;32m    298\u001B[0m     _, Hv \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataloader_hv_product(v)\n\u001B[1;32m    299\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 300\u001B[0m     Hv \u001B[38;5;241m=\u001B[39m \u001B[43mhessian_vector_product\u001B[49m\u001B[43m(\u001B[49m\u001B[43mi_grad\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mi_param\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    301\u001B[0m trace_vhv\u001B[38;5;241m.\u001B[39mappend(group_product(Hv, v)\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mitem())\n\u001B[1;32m    302\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mabs\u001B[39m(np\u001B[38;5;241m.\u001B[39mmean(trace_vhv) \u001B[38;5;241m-\u001B[39m trace) \u001B[38;5;241m/\u001B[39m (\u001B[38;5;28mabs\u001B[39m(trace) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1e-6\u001B[39m) \u001B[38;5;241m<\u001B[39m tol:\n",
      "File \u001B[0;32m~/diff-ViT/pyhessian/utils.py:91\u001B[0m, in \u001B[0;36mhessian_vector_product\u001B[0;34m(gradsH, params, v)\u001B[0m\n\u001B[1;32m     84\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mhessian_vector_product\u001B[39m(gradsH, params, v):\n\u001B[1;32m     85\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     86\u001B[0m \u001B[38;5;124;03m    compute the hessian vector product of Hv, where\u001B[39;00m\n\u001B[1;32m     87\u001B[0m \u001B[38;5;124;03m    gradsH is the gradient at the current point,\u001B[39;00m\n\u001B[1;32m     88\u001B[0m \u001B[38;5;124;03m    params is the corresponding variables,\u001B[39;00m\n\u001B[1;32m     89\u001B[0m \u001B[38;5;124;03m    v is the vector.\u001B[39;00m\n\u001B[1;32m     90\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 91\u001B[0m     hv \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgrad\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgradsH\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     92\u001B[0m \u001B[43m                             \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     93\u001B[0m \u001B[43m                             \u001B[49m\u001B[43mgrad_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     94\u001B[0m \u001B[43m                             \u001B[49m\u001B[43monly_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     95\u001B[0m \u001B[43m                             \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m hv\n",
      "File \u001B[0;32m/opt/conda/envs/diffvit/lib/python3.9/site-packages/torch/autograd/__init__.py:436\u001B[0m, in \u001B[0;36mgrad\u001B[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001B[0m\n\u001B[1;32m    432\u001B[0m     result \u001B[38;5;241m=\u001B[39m _vmap_internals\u001B[38;5;241m.\u001B[39m_vmap(vjp, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m, allow_none_pass_through\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)(\n\u001B[1;32m    433\u001B[0m         grad_outputs_\n\u001B[1;32m    434\u001B[0m     )\n\u001B[1;32m    435\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 436\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    437\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    438\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrad_outputs_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    439\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    440\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    441\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    442\u001B[0m \u001B[43m        \u001B[49m\u001B[43mallow_unused\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    443\u001B[0m \u001B[43m        \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    444\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    445\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m materialize_grads:\n\u001B[1;32m    446\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28many\u001B[39m(\n\u001B[1;32m    447\u001B[0m         result[i] \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_tensor_like(inputs[i])\n\u001B[1;32m    448\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(inputs))\n\u001B[1;32m    449\u001B[0m     ):\n",
      "File \u001B[0;32m/opt/conda/envs/diffvit/lib/python3.9/site-packages/torch/autograd/graph.py:769\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[0;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[1;32m    767\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[1;32m    768\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 769\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    770\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    771\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    772\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    773\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[0;31mRuntimeError\u001B[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "from pyhessian import DDVHessian\n",
    "# Example: Select specific layers (e.g., layers 10, 20, 30)\n",
    "selected_layer_indices = [30]\n",
    "\n",
    "print(\"Calculating the sensitivities via the averaged Hessian trace...\")\n",
    "batch_num = 10\n",
    "trace_list = []\n",
    "not_quantized_model.eval()\n",
    "for i, (inputs, labels) in enumerate(train_loader):\n",
    "    adv_inputs = not_quantized_attack_net.gen_adv_inputs(inputs, labels)\n",
    "    inputs, targets = inputs.cuda(), labels.cuda()\n",
    "\n",
    "    # Initialize the DDVHessian class with selected layers\n",
    "    hessian_comp = DDVHessian(\n",
    "        model=not_quantized_model,\n",
    "        q_model=int4_model,\n",
    "        criterion=torch.nn.MSELoss(),\n",
    "        data=(inputs, labels),\n",
    "        adv_data=(adv_inputs, labels),\n",
    "        attack_net=not_quantized_attack_net,\n",
    "        layer_indices=selected_layer_indices,\n",
    "        cuda=args.device\n",
    "    )\n",
    "    print(f\"Processing batch {i + 1}/{batch_num}\")\n",
    "    name, trace = hessian_comp.trace()\n",
    "    trace_list.append(trace)\n",
    "    if i == batch_num - 1:\n",
    "        break\n",
    "\n",
    "# Process the trace_list as needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffvit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
